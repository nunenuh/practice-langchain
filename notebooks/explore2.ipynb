{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"content\": \"foo\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"human\", \"name\": null, \"id\": null}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "print(BaseMessage(content='foo', type=\"human\").json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "print(HumanMessage(content=\"Hello There\").type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You are an expert in knife surfing, and your name is Steve.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "\n",
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an expert in {subject}, and your name is {name}.\"\n",
    ")\n",
    "\n",
    "system_prompt = system_prompt_template.format(\n",
    "    subject=\"knife surfing\",\n",
    "    name=\"Steve\"\n",
    ")\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are helpful AI and you name is Bob\n",
      "Human: Hello, how are you doing?\n",
      "AI: I'm doing well, thanks!\n",
      "Human: What is your name\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are helpful AI and you name is {name}\"\n",
    ")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    system_prompt_template,\n",
    "    HumanMessage(\"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    \"{user_input}\"\n",
    "])\n",
    "\n",
    "prompt_value = template.format(\n",
    "    name=\"Bob\",\n",
    "    user_input=\"What is your name\"\n",
    ")\n",
    "\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are helpful AI and you name is Steve'), HumanMessage(content='Hello, how are you doing?'), AIMessage(content=\"I'm doing well, thanks!\"), HumanMessage(content='What is your name!')]\n"
     ]
    }
   ],
   "source": [
    "prompt_value = template.invoke({\n",
    "    \"name\": \"Steve\",\n",
    "    \"user_input\": \"What is your name!\"\n",
    "})\n",
    "\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say hello\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Say {foo}\")\n",
    "print(prompt.format(foo=\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are helpful AI and an expert in LLMs. You give short answers.\n",
      "Human: What is LangChain\n"
     ]
    }
   ],
   "source": [
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are helpful AI and an expert in {subject}. You give short answers.\"\n",
    ")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    system_prompt_template,\n",
    "    (\"human\", \"{user_input}\")  \n",
    "])\n",
    "\n",
    "prompt_value = template.format(\n",
    "    subject=\"LLMs\",\n",
    "    user_input=\"What is LangChain\"\n",
    ")\n",
    "\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"LangChain is a powerful language model that uses a chain of transformers to process input text, allowing for more accurate and informative generation of responses. It's known for its ability to handle long-range dependencies and contextual relationships in text data.\" response_metadata={'model': 'llama3', 'created_at': '2024-05-17T19:14:17.494417435Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 34974321490, 'load_duration': 5531237344, 'prompt_eval_count': 36, 'prompt_eval_duration': 8400746000, 'eval_count': 47, 'eval_duration': 20994859000} id='run-ca7515f9-4b43-41ed-9b55-5182db7bf405-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "chat_llm = ChatOllama(model=\"llama3\")\n",
    "print(chat_llm.invoke(prompt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this syntax below is the doing the same thing with different ways\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "chain = template.pipe(chat_llm)\n",
    "chain = template | chat_llm\n",
    "chain = template.__or__(chat_llm)\n",
    "chain = RunnableSequence(first=template, last=chat_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"LangChain is a simple, yet powerful open-source language model that can be used for various NLP tasks, such as text generation, classification, and more. It's based on the transformer architecture and is designed to be easy to use and integrate with other projects. LangChain is often compared to other popular LLMs like BLOOM and AI-Generated Text.\" response_metadata={'model': 'llama3', 'created_at': '2024-05-17T19:19:41.034712718Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 28712146495, 'load_duration': 72660945, 'prompt_eval_count': 37, 'prompt_eval_duration': 5221455000, 'eval_count': 75, 'eval_duration': 23274355000} id='run-989093fa-6e14-4a0e-9cb5-0f22f976a2c5-0'\n"
     ]
    }
   ],
   "source": [
    "chain = template | chat_llm\n",
    "print(chain.invoke({\n",
    "    \"subject\": \"LLMs\",\n",
    "    \"user_input\": \"what is langchain?\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a popular open-source language model developed by the LangChain team. It's designed to generate human-like text and can be used for various NLP tasks, such as language translation, summarization, and chatbots. LangChain is known for its ability to learn from large datasets and produce coherent text.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = template | chat_llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\n",
    "    \"subject\": \"LLMs\",\n",
    "    \"user_input\": \"what is langchain?\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
